# LLM finetuning

This is a small collection of jupyter notebooks which act as supporting documentation to the following medium articles:
- [Multilabel Classification using Mistral-7B on a single GPU with quantization and LoRA](https://medium.com/@lukas.hauzenberger/multilabel-classification-using-mistral-7b-on-a-single-gpu-with-quantization-and-lora-8f848b5237f3)
- [Efficient LLM Pretraining: Packed Sequences and Masked Attention](https://medium.com/@lukas.hauzenberger/efficient-llm-pretraining-packed-sequences-and-masked-attention-351d2a43b719)
